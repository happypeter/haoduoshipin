国内以前有个词叫万维网，对应英文就是 Web ，另一个词叫因特网，对应 Internet 。但是后来这两个中文翻译都死掉了，目前大家说互联网比较多。而每次提到互联网，其实通常是指 Web ，也就是由无数网页通过 HTTP 协议连接而成的网。Web 从诞生到现在为止，都是以中心化的 client/server 架构存在的，但是今天我们要讨论的是 Web 的未来，是 P2P 架构的 Web 。

## 传统 Web 架构

咱们先复习一下传统的 client/server 架构的 Web 。

写好网站之后，我们会把它部署到服务器上。用户会通过自己机器上的客户端程序，通常也就是浏览器了，去下载这个网站的文件，然后运行里面的 html/css/js 代码，得到网页。但是要注意，这种架构本身不是 Web 的本质。Web 的本质是很多网页通过超级链接，来相互连接到组成一个网。

但是后来，所谓的 Web2.0 来了，用户可以往服务器上提交内容了。例如，用户可以给维基百科添加新内容，或者可以在 Twitter 上注册新账户，而这些操作需要在服务器上安装数据库，同时网站也拥有了自己的服务器端代码。Web2.0 时代，网站拥有了很多功能，变成了 Web App 。 Web App 跟普通 App 不一样，普通 App 是直接安装在用户设备上的，但是 Web App 却是存在于服务器上，所以所整个 Web App 架构的核心其实是服务器。

最近十几年来，人们对这种服务器为中心架构非常喜欢，提出了云计算的概念，提出了 Saas 的概念，有大量的文章讨论过这种架构为何大大优于传统 App 架构。

## 传统架构的中心化问题

但是传统的这种 Web 架构，有着自己的中心化问题。

首先第一个问题是，大家都要去一台服务器上去挤，性能瓶颈明显。比如我要给你传递一个文件，虽然咱俩的计算机其实都是接入互联网的，但是我们是不能直接把文件从我的机器传直接递给你的机器的，而必须要经过服务器，例如 Dropbox 或者 Google Drive 的服务器。很明显，中间经过服务器这一步是没有必要的，很多人要传互相传文件，都走一个服务器，服务器压力很大。这些都是因为 Web 架构是 client/server 模式的，所有的公司的业务也都基于这个模式来运行，尽管本质上这种模式明显是有问题的。

第二个问题是隐私很难得到有效保护，数据所有权也很不清晰。因为所有的数据传递都经过服务器，所以服务器的拥有者，也就是商业公司，就能把持我们的数据。也就是说，不管我们是发邮件还是聊天，数据都是可以被第三方看到的。数据一般都是直接在服务器上明文存储的，攻击者只要拿下一台服务器，就能获得数以万计的用户数据，所以说用户的隐私是没有安全保障的。另外，用户的数据一旦存到服务器上，公司就会认为这些数据属于他们了，所以数据所有权不清晰，最近几年也成了一个很大的一个社会问题。

总之，中心化 Web 的问题主要表现在性能瓶颈明显，以及数据所有权不清。

## P2P Web 的优势

如果未来 Web 改成了 P2P 架构，那么用户的隐私就可以得到保护，可以真正拥有自己的数据。

我们来说说 P2P Web 的基本原理。首先网站完全属于用户，没有一个中央服务器。所有文件的存储都是分布式的，都是 P2P 的，每个用户的机器都同时是客户端和服务器。我们发布网站的时候，只需要发布到自己的计算机上就可以，网站的访客越多，服务器也就越多，因为每个访客的数据都会被缓存，这样他们就成了服务器。同时每个人都会访问就近的服务器，减轻了网络压力。每个网站的链接不再是一个 URL ，而是一个哈希，或者是默克尔根 https://zhuanlan.zhihu.com/p/45233496 。这样做的好处是，即使网站的所有文件分散到不同的服务器，而且这些服务器也不能全部保证安全和随时在线，但只要服务器足够多，那么网站数据也照样可以完好的下载到访客的机器上。所以也可以说，所有访问过我网站的机器，会组成一个分部式的服务器集群。

P2P Web 的好处也非常明显。一个是便宜，因为不用买服务器了。第二个是性能好，如果我的内容真的好，访客多了起来，那么相当与我的分布式服务器集群也会越来越强大，这个不需要我花钱。第三个是可以做很多以前不可想象的事情，同一个网站，例如 facebook ，可以有无数个版本，每个人都可以拥有自己独一无二的版本。理解默克尔树的概念之后，我们就会知道，其实这样网络上也不会浪费存储资源，因为多出来需要保存的只是数据的差异部分。每个版本通过一个新的哈希来发布，其他人只有拿到哈希，就可以访问到我的这个版本的网站了，也是非常的简单。

P2P Web 最大的一个优势可能就是数据终于掌握在用户自己的手里了。没有了中央服务器，当然也就没有了中心化的数据库。那么如果我们做一个 P2P 的 twitter ，然后上去注册一个新用户，那数据到底存放到哪里呢？这里要沿用的还是 Unix 哲学，一切皆文件。我自己的各项数据，是保存到一个 json 文件中的，而这个文件，如果我不去专门授权，也只能被我自己的机器访问，渲染出一个独一无二版本的属于我自己的网站。当然，我发布的一条 twitter 数据后，会授权我的好友去下载的。我的好友会根据我网站的哈希找到数据，下载到他们的机器上生去成他们自己的页面，而他们的点赞和评论数据也可以授权给我，我的机器上就可以用这些数据来渲染我的那个网站了。这样，常规的网站功能一样可以运行，同时数据的所属权是非常清晰的。更多的技术细节可以参考 P2P Web 浏览器 Beaker 的官网 https://beakerbrowser.com/docs/tour/ 。

总之，有了 P2P 的 Web 以前的很多中心化问题现在就变得不是问题了。

## 总结

关于 P2P 架构的 Web ，主体内容就是这些了。总结起来，传统的以 HTTP 连接起来的 client/server 模式的 Web 有着自己的各种中心化问题，例如性能容易遭遇瓶颈和非常不清晰的数据所有权。而 P2P 架构下，每个人都是服务器，数据就近访问，性能瓶颈不存在了，同时，每个人都只能获得自己的数据以及别人授权访问的数据，所以数据的所有权非常的清晰。

参考

- https://www.youtube.com/watch?v=ZrUHx-bnfZI
